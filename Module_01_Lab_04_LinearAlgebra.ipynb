{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srijhanavi/FMML_LABS_AND_PROJECTS/blob/main/Module_01_Lab_04_LinearAlgebra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU9LZjQxiQT2"
      },
      "source": [
        "# Transforming data using linear algebra\n",
        "\n",
        "FMML Module 1, Lab 4<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KBe4ZA32UTbv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7mqG-dafVpya"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "\n",
        "from IPython.display import Latex as lt\n",
        "#Plotting functions\n",
        "#(You DON'T need to understand how these functions)\n",
        "\n",
        "# function to plot a grid\n",
        "def plotGrid(transform, unit, linestyle = ':', fig=None, ax=None):\n",
        "  lim1 = -100\n",
        "  lim2 = 100\n",
        "  def mat2xy(start, end):\n",
        "    if len(start.shape)==1:\n",
        "      start = np.expand_dims(start,0)\n",
        "      end = np.expand_dims(end,0)\n",
        "    nan = np.ones(len(start))*np.nan\n",
        "    x = np.stack((start[:,0], end[:,0], nan)).T.reshape(-1)\n",
        "    y = np.stack((start[:,1], end[:,1], nan)).T.reshape(-1)\n",
        "    return x, y\n",
        "\n",
        "  def parallellines(axis, addend, lines, unit):\n",
        "    addend = np.repeat(np.expand_dims(addend,0), lines*2, 0)\n",
        "    unit = np.expand_dims(np.arange(-lines, lines)*unit,1)\n",
        "    unit = unit-lines\n",
        "    addend = addend*unit\n",
        "    lines = np.expand_dims(axis,0) + addend\n",
        "    return np.concatenate((lines, lines*-1))\n",
        "\n",
        "  if fig is None:\n",
        "    fig, ax = plt.subplots(figsize=(10,10))\n",
        "  transform = transform.astype(np.float)\n",
        "  xaxis = transform[0]\n",
        "  yaxis = transform[1]\n",
        "\n",
        "  # plot lines parallel to the x axis\n",
        "  lines1= parallellines(xaxis*lim1, yaxis, 100,unit )\n",
        "  lines2 = parallellines(xaxis*lim2, yaxis, 100,unit )\n",
        "  x,y = mat2xy(lines1, lines2)\n",
        "  plt.plot(x,y, linestyle+'k', linewidth=0.5)\n",
        "  # plot x axis\n",
        "  x,y = mat2xy(xaxis*lim1, xaxis*lim2)\n",
        "  plt.plot(x,y,linestyle, color = '#440077')\n",
        "\n",
        "  # plot  lines parallel to the y axis\n",
        "  lines1= parallellines(yaxis*lim1, xaxis, 100,unit)\n",
        "  lines2 = parallellines(yaxis*lim2, xaxis, 100,unit)\n",
        "  x,y = mat2xy(lines1, lines2)\n",
        "  plt.plot(x,y, linestyle+'k', linewidth=0.5)\n",
        "  # plot y axis\n",
        "  x,y = mat2xy(yaxis*lim1, yaxis*lim2)\n",
        "  plt.plot(x,y,linestyle, color= '#aa5500')\n",
        "\n",
        "  return fig, ax\n",
        "\n",
        "def plotData(X, y, xlabel = 'hole', ylabel = 'bound', fig=None, ax = None):\n",
        "\n",
        "  if fig is None:\n",
        "    fig, ax = plt.subplots()\n",
        "  for ii in range(nclasses):\n",
        "    plt.scatter(X[y==ii,0], X[y==ii, 1])\n",
        "  plt.legend([str(i) for i in range(nclasses)])\n",
        "  plt.xlabel(xlabel)\n",
        "  plt.ylabel(ylabel)\n",
        "  lim2 = X.max()\n",
        "  lim1 = X.min()\n",
        "  add = abs(lim1-lim2)/5\n",
        "  return fig, ax\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d5dmEXxaktp"
      },
      "source": [
        "# Matrix transformations on data\n",
        "\n",
        "A 2D coordinate system is defined by its basis vectors, i and j. In the standard coordinate system (Let us call it T0), the basis vectors are\n",
        "\n",
        "$$\\begin{equation}\n",
        "i = \\left\\{  \\begin{aligned}1 \\\\ 0 \\end{aligned} \\right\\}\n",
        "\\end{equation}$$\n",
        "and\n",
        "$$\\begin{equation} j = \\left\\{ \\begin{aligned} 0 \\\\ 1\\end{aligned} \\right\\} \\end{equation}$$\n",
        "\n",
        "We can use any two vectors as basis vectors for a new coordinate system as long as they are not colinear. For example, let us call this new coordinate system T1:\n",
        "\n",
        "$$\\begin{equation}\n",
        "i = \\left\\{  \\begin{aligned}1 \\\\ -1 \\end{aligned} \\right\\}\n",
        "\\end{equation}$$\n",
        "and\n",
        "$$\\begin{equation} j = \\left\\{ \\begin{aligned} 0 \\\\ 2 \\end{aligned} \\right\\} \\end{equation}$$\n",
        "\n",
        "Suppose we have a point [a,b] in the T1 coordinate system. Its representation in the standard system T0 can be obtained by the following matrix multiplication:\n",
        "\n",
        "$$ \\begin{equation}\n",
        "\\left\\{  \\begin{aligned}a' \\\\ b' \\end{aligned} \\right\\} =\n",
        "\\left\\{  \\begin{aligned}&1 & 0 \\\\ -&1 & 2 \\end{aligned} \\right\\}\n",
        "\\left\\{  \\begin{aligned}a \\\\ b \\end{aligned} \\right\\}\n",
        "\\end{equation}$$\n",
        "where the columns of the matrix are the basis vectors of T1.\n",
        "\n",
        "Let us see this in action:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8SCFKqfbM-l",
        "outputId": "12cfb180-fff5-4718-ec3f-acada629bccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data in T0 =  [5 3]\n",
            "Data in T1 =  [5 4]\n"
          ]
        }
      ],
      "source": [
        "T0 = np.array([[1,0],[0,1]])\n",
        "T1 = np.array([[1,0], [-1,2]])\n",
        "\n",
        "data1 = np.array([5,4]) # the data in T1 coordinate system\n",
        "data0 = np.matmul(T1, data1) # the data in T0 coordinate system\n",
        "\n",
        "print('Data in T0 = ', data0)\n",
        "print('Data in T1 = ', data1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIfEWZ1RQeve"
      },
      "source": [
        "We can visualize this below. T0 is shown with dotted lines and T1 is shown with solid lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "jSuTaeSDQoYK",
        "outputId": "6fe7112b-49f9-4a02-b62f-b31229b0f1d0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-80b5d7444514>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplotGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# custom plotting function, no need to understand this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplotGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# custom plotting function, no need to understand this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plotGrid' is not defined"
          ]
        }
      ],
      "source": [
        "fig, ax = plotGrid(T1.T, 1,'-') # custom plotting function, no need to understand this\n",
        "plotGrid(T0.T, 1, fig=fig, ax=ax) # custom plotting function, no need to understand this\n",
        "plt.scatter(data0[0], data0[1])\n",
        "ax.set_xlim(-10,10)\n",
        "ax.set_ylim(-10,10)\n",
        "ax.set_xticks([]);\n",
        "ax.set_yticks([]);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUb3oYWIgdya"
      },
      "source": [
        "Look at the coordinates of the blue dot. In T0 (dotted lines), the position is [5,3] where it is [5,4] in T1. Feel free to experiment with different data points and coordinate systems.\n",
        "\n",
        "Remember that we can achieve the same thing by post-multiplying the transpose of the transformation matrix to the data. This will come in handy when transforming multiple data points at once:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD4pqOMndf-4",
        "outputId": "4f8d034a-9e56-4e46-b700-57c24bd370fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 3]\n",
            "[5 3]\n"
          ]
        }
      ],
      "source": [
        "data0_a = np.matmul(T1, data1)\n",
        "data0_b = np.matmul(data1, T1.T)\n",
        "print(data0_a)\n",
        "print(data0_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-Kui3dSESPm"
      },
      "source": [
        "Why is transforming data useful? Data transformations cause the distance between data points to change. This will affect distance-based algorithms such as nearest neighbour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE0NbpYIC9ou",
        "outputId": "fe097568-55fb-4580-e240-a01b8c351910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance between A and B in T1 =  8.06225774829855\n",
            "Distance between B and C in T1 =  4.123105625617661\n",
            "Distance between A and C in T1 =  4.47213595499958\n",
            "\n",
            "Distance between A and B in T0 =  15.033296378372908\n",
            "Distance between B and C in T0 =  9.055385138137417\n",
            "Distance between A and C in T0 =  6.324555320336759\n"
          ]
        }
      ],
      "source": [
        "# let us define 3 points in T1\n",
        "A1 = np.array([3,3])\n",
        "B1 = np.array([2,-5])\n",
        "C1 = np.array([1,-1])\n",
        "\n",
        "# the corresponding points in T0:\n",
        "A0 = np.matmul(T1, A1)\n",
        "B0 = np.matmul(T1, B1)\n",
        "C0 = np.matmul(T1, C1)\n",
        "\n",
        "# function to calculate Euclidean distance:\n",
        "def dist(a, b):\n",
        "  diff = a-b\n",
        "  sq = diff*diff\n",
        "  return np.sqrt(sq.sum())\n",
        "\n",
        "# distance between the points in T1\n",
        "print('Distance between A and B in T1 = ', dist(A1, B1))\n",
        "print('Distance between B and C in T1 = ', dist(B1, C1))\n",
        "print('Distance between A and C in T1 = ', dist(A1, C1))\n",
        "\n",
        "print('')\n",
        "# distnace between the points in T0\n",
        "print('Distance between A and B in T0 = ', dist(A0, B0))\n",
        "print('Distance between B and C in T0 = ', dist(B0, C0))\n",
        "print('Distance between A and C in T0 = ', dist(A0, C0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE95JMniUtDm"
      },
      "source": [
        "We see that in T1, B and C are the closest whereas in T0, A and C are the closest. These kinds of changes will affect the predictions returned by the nearest neighbour algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFbpTSBdV29C"
      },
      "source": [
        "# Transformations on MNIST\n",
        "\n",
        "Let us experiment with a subset of the MNIST dataset. We will extract two features from the database for our experiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMvUzC2GUawS"
      },
      "source": [
        "Functions for nearest neighbour, accuracy and feature extraction. (from previous labs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "22ayl0sViF5-"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "\n",
        "def NN1(traindata, trainlabel, query):\n",
        "  diff  = traindata - query  # find the difference between features. Numpy automatically takes care of the size here\n",
        "  sq = diff*diff # square the differences\n",
        "  dist = sq.sum(1) # add up the squares\n",
        "  label = trainlabel[np.argmin(dist)] # our predicted label is the label of the training data which has the least distance from the query\n",
        "  return label\n",
        "\n",
        "def NN(traindata, trainlabel, testdata):\n",
        "  # we will run nearest neighbour for each sample in the test data\n",
        "  # and collect the predicted classes in an array using list comprehension\n",
        "  predlabel = np.array([NN1(traindata, trainlabel, i) for i in testdata])\n",
        "  return predlabel\n",
        "\n",
        "def Accuracy(gtlabel, predlabel):\n",
        "  assert len(gtlabel)==len(predlabel), \"Length of the groundtruth labels and predicted labels should be the same\"\n",
        "  correct = (gtlabel==predlabel).sum() # count the number of times the groundtruth label is equal to the predicted label.\n",
        "  return correct/len(gtlabel)\n",
        "\n",
        "def cumArray(img):\n",
        "  img2 = img.copy()\n",
        "  for ii in range(1, img2.shape[1]):\n",
        "    img2[ii,:] = img2[ii,:] + img2[ii-1,:]  # for every row, add up all the rows above it.\n",
        "  img2 = img2>0\n",
        "  return img2\n",
        "\n",
        "def getHolePixels(img):\n",
        "  im1 = cumArray(img)\n",
        "  im2 = np.rot90(cumArray(np.rot90(img)), 3) # rotate and cumulate it again for differnt direction\n",
        "  im3 = np.rot90(cumArray(np.rot90(img, 2)), 2)\n",
        "  im4 = np.rot90(cumArray(np.rot90(img, 3)), 1)\n",
        "  hull =  im1 & im2 & im3 & im4 # this will create a binary image with all the holes filled in.\n",
        "  hole = hull & ~ (img>0) # remove the original digit to leave behind the holes\n",
        "  return hole\n",
        "\n",
        "def getHullPixels(img):\n",
        "  im1 = cumArray(img)\n",
        "  im2 = np.rot90(cumArray(np.rot90(img)), 3) # rotate and cumulate it again for differnt direction\n",
        "  im3 = np.rot90(cumArray(np.rot90(img, 2)), 2)\n",
        "  im4 = np.rot90(cumArray(np.rot90(img, 3)), 1)\n",
        "  hull =  im1 & im2 & im3 & im4 # this will create a binary image with all the holes filled in.\n",
        "  return hull\n",
        "\n",
        "def minus(a, b):\n",
        "  return a & ~ b\n",
        "\n",
        "def getBoundaryPixels(img):\n",
        "  img = img.copy()>0  # binarize the image\n",
        "  rshift = np.roll(img, 1, 1)\n",
        "  lshift = np.roll(img, -1 ,1)\n",
        "  ushift = np.roll(img, -1, 0)\n",
        "  dshift = np.roll(img, 1, 0)\n",
        "  boundary = minus(img, rshift) | minus(img, lshift) | minus(img, ushift) | minus(img, dshift)\n",
        "  return boundary\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzF-9mGxUkWC"
      },
      "source": [
        "Get the MNIST dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHz5BVmLUjzb",
        "outputId": "5da0fecd-d243-49d2-aeff-075f4156b153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#loading the dataset\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "train_X = train_X/255\n",
        "test_X = test_X/255\n",
        "\n",
        "nclasses = 4\n",
        "\n",
        "# get only for the first 4 classes\n",
        "train_X = train_X[train_y<nclasses]\n",
        "train_y = train_y[train_y<nclasses]\n",
        "test_X = test_X[test_y<nclasses]\n",
        "test_y = test_y[test_y<nclasses]\n",
        "\n",
        "train_X = train_X[::100].copy() # We are only taking a subset of the training set\n",
        "train_y = train_y[::100].copy() # do the same to the labels\n",
        "test_X = test_X[::100].copy() # taking a subset of the test set. This code takes every 500th sample\n",
        "test_y = test_y[::100].copy()\n",
        "\n",
        "# get all the features\n",
        "train_hole = np.array([getHolePixels(i).sum() for i in train_X])\n",
        "test_hole = np.array([getHolePixels(i).sum() for i in test_X])\n",
        "train_bound = np.array([getBoundaryPixels(i).sum() for i in train_X])\n",
        "test_bound = np.array([getBoundaryPixels(i).sum() for i in test_X])\n",
        "# train_hull = np.array([getHullPixels(i).sum() for i in train_X])\n",
        "# test_hull = np.array([getHullPixels(i).sum() for i in test_X])\n",
        "# train_sum = np.sum(train_X, (1,2))/(28*28)\n",
        "# test_sum = np.sum(test_X, (1,2))/(28*28)\n",
        "\n",
        "# create the train and test set by combining the appropriate features\n",
        "train_feats = np.vstack((train_hole,train_bound)).transpose()\n",
        "test_feats = np.vstack((test_hole, test_bound)).transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7qGVrlnQCUy"
      },
      "source": [
        "Let us plot the samples and see what they look like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "saRzHfi9QAGd",
        "outputId": "78058c62-cd7d-41cf-d8a9-90c9d3b9bf3c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-54ca70d68d84>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mxlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mylim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplotData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plotData' is not defined"
          ]
        }
      ],
      "source": [
        "# fix limits of x and y axis so that we can see what is going on\n",
        "xlim=[-100,300]\n",
        "ylim=[-100,300]\n",
        "fig, ax = plotData(train_feats, train_y)\n",
        "ax.set_xlim(xlim)\n",
        "ax.set_ylim(ylim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCb4DikQP1ck"
      },
      "source": [
        "Check the baseline accuracy on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxVr6bd9PzlI",
        "outputId": "50e2ec57-d775-4e91-d006-76a41b676e2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy =  0.7619047619047619\n"
          ]
        }
      ],
      "source": [
        "test_pred = NN(train_feats, train_y, test_feats)\n",
        "acc = Accuracy(test_y, test_pred)\n",
        "print('Baseline accuracy = ', acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl8Noo8pZRek"
      },
      "source": [
        "Let us try transforming the features and checking their accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8dUPWRsEZKwo"
      },
      "outputs": [],
      "source": [
        "transform = np.array([[0.5,-0.5],[0,2.5]])\n",
        "\n",
        "train_feats_t = np.matmul(train_feats, transform)\n",
        "test_feats_t = np.matmul(test_feats, transform)  # whatever transform we are applying to the training set should be applied to the test set also"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqMBUAfqIUcC",
        "outputId": "58cbeb8b-59af-45fc-b4b3-ea954221ef32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.5 -0.5]\n",
            " [ 0.   2.5]]\n"
          ]
        }
      ],
      "source": [
        "print(transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "iRH4VckHZaWv",
        "outputId": "59f8c00b-5a95-4169-850f-e1a31386eb82"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-392d3754ac5b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplotData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_feats_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plotData' is not defined"
          ]
        }
      ],
      "source": [
        "fig, ax = plotData(train_feats_t, train_y)\n",
        "ax.set_xlim(xlim)\n",
        "ax.set_ylim(ylim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9fknczfZdYF",
        "outputId": "d20a36a1-67a9-4a36-adcd-341c0cbb5b6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after transform =  0.8095238095238095\n"
          ]
        }
      ],
      "source": [
        "test_pred = NN(train_feats_t, train_y, test_feats_t)\n",
        "acc = Accuracy(test_y, test_pred)\n",
        "print('Accuracy after transform = ', acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFBQlAnNZ3on"
      },
      "source": [
        "## Questions:\n",
        "1. Experiment with different transformation matrices and check the accuracy\n",
        "2. Will the same transform used for these two features also work for other features?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2:The suitability of a particular transformation for multiple features in your dataset depends on the nature of the features, the problem you're trying to solve, and how the features respond to the transformation. Here are some considerations:\n",
        "\n",
        "1. **Geometric Transformations:** If you are applying geometric transformations like rotation, translation, or scaling, these transformations are typically feature-agnostic. They modify the entire image uniformly. As a result, they can work well for various features within the image, as long as the features are spatially invariant, and their relationships and characteristics do not change significantly under the transformation.\n",
        "\n",
        "2. **Content and Semantic Meaning:** Some features within an image may have specific content or semantic meaning that is sensitive to certain transformations. For example, if you're working with text recognition and you apply a rotation transformation, the rotation may significantly affect the legibility of the text. In such cases, the same transformation may not work equally well for all features.\n",
        "\n",
        "3. **Feature Detection and Localization:** Depending on the features and the transformation, you may need to consider feature detection and localization. Some features may require specific attention or specialized transformations to ensure that they are accurately identified and preserved.\n",
        "\n",
        "4. **Augmentation Strategies:** In practice, it's common to apply different augmentations to different features or regions of interest within an image. For example, you might apply translation and rotation to the entire image but apply a specific transformation to a region of interest, like object detection or semantic segmentation.\n",
        "\n",
        "5. **Problem-Specific Considerations:** The choice of transformations should be guided by the specific problem you're trying to solve. For certain tasks, such as object recognition or detection, you may need to design augmentation strategies that are tailored to the characteristics and invariances of the objects or features of interest.\n",
        "\n",
        "In summary, while geometric transformations can often be applied uniformly to an entire image and are feature-agnostic, you should consider the unique characteristics and requirements of the features in your dataset. Depending on the problem, it may be beneficial to apply different transformations to different features or regions to preserve their semantic meaning and enhance the model's ability to learn and generalize effectively. Your choice of transformations should align with the goals and challenges of your specific task."
      ],
      "metadata": {
        "id": "U1SXLbqnvQst"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1:\n",
        "Experimenting with different transformation matrices can be a valuable approach to assess the impact of geometric transformations on the accuracy of your model. Transformation matrices are commonly used for tasks like image rotation, translation, scaling, and shearing. Here's a high-level outline of how you can carry out this experiment:\n",
        "\n",
        "Data Preparation:\n",
        "\n",
        "Prepare your dataset, including the training, validation, and test sets.\n",
        "Select Transformation Matrices:\n",
        "\n",
        "Decide which transformation matrices you want to experiment with. For example, you can explore rotations, translations, scalings, and shear transformations. Each transformation has its own matrix representation.\n",
        "Augmentation Pipeline:\n",
        "\n",
        "Create an augmentation pipeline for each transformation matrix. For example, if you're experimenting with rotations, your pipeline should include random rotation within a specified range (e.g., -30 to +30 degrees).\n",
        "Training and Evaluation:\n",
        "\n",
        "Train your model multiple times, each time using a different transformation matrix in the augmentation pipeline. You can also vary the range or parameters of each transformation to assess its impact on model performance.\n",
        "Evaluation Metrics:\n",
        "\n",
        "Record and compare the accuracy, as well as other relevant evaluation metrics (e.g., loss, precision, recall), for each experiment using different transformation matrices.\n",
        "Cross-Validation:\n",
        "\n",
        "If you have a small dataset, consider using cross-validation to obtain more robust results and to assess the impact of transformation matrices across different data splits.\n",
        "Iterative Experimentation:\n",
        "\n",
        "Experiment with various combinations of transformations and their parameters to identify the ones that lead to the best model performance.\n",
        "Visualization:\n",
        "\n",
        "Optionally, visualize the effects of different transformations on sample images to gain insights into how each transformation impacts the dataset.\n",
        "Compare Results:\n",
        "\n",
        "Analyze and compare the results to determine which transformation matrices contribute to improved model accuracy.\n",
        "Optimize Augmentation Strategies:\n",
        "\n",
        "Based on your findings, refine your augmentation strategies by selecting the most effective transformation matrices and their associated parameters for your specific proble"
      ],
      "metadata": {
        "id": "_hJ2r2ZCu7nB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36TOA47xak20"
      },
      "source": [
        "# Data normalization\n",
        "\n",
        "Sometimes the features of our data have vastly different scales. This will cause the learning algorithm to give more importance to certain features, reducing its performance. Data normalization is a method in which we transform the features so that they have similar scales.\n",
        "\n",
        "Three commonly used feature scaling techniques are rescaling, mean normalization and z-score normalization. Here, we will talk about the simplest one: rescaling.\n",
        "\n",
        "$$\\begin{equation}\n",
        "x' = \\frac {x -min(x)} { max(x) - min(x)}\n",
        "\\end{equation}$$\n",
        "\n",
        "\n",
        "\n",
        "For more information, see [this page](https://towardsdatascience.com/data-normalization-in-machine-learning-395fdec69d02)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ni19QKDLZzeo"
      },
      "outputs": [],
      "source": [
        "def rescale(data):\n",
        "  return (data - data.min())/(data.max() - data.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k83ZMtKeZrQ"
      },
      "source": [
        "We have to apply the rescaling to each feature individually. Also remember to apply the same transform we are using on the train set to the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1JLOPwhvehpR"
      },
      "outputs": [],
      "source": [
        "train_feats_rescaled_x = rescale(train_feats[:,0])\n",
        "train_feats_rescaled_y = rescale(train_feats[:,1])\n",
        "train_feats_rescaled = np.stack((train_feats_rescaled_x, train_feats_rescaled_y),1)\n",
        "\n",
        "test_feats_rescaled_x = rescale(test_feats[:,0])\n",
        "test_feats_rescaled_y = rescale(test_feats[:,1])\n",
        "test_feats_rescaled = np.stack((test_feats_rescaled_x, test_feats_rescaled_y),1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaZVy9vxfKwX"
      },
      "source": [
        "Let us plot the rescaled features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "LXyatpwZevOH",
        "outputId": "208ee095-e035-451f-acd8-6759ec445d76"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-eb755dee695e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplotData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_feats_rescaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'plotData' is not defined"
          ]
        }
      ],
      "source": [
        "fig, ax = plotData(train_feats_rescaled, train_y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjBgxE6zglsL"
      },
      "source": [
        "This type of rescaling makes all the features between 0 and 1.\n",
        "\n",
        "Let us calculate the accuracy obtained by this transform:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hKQnsj-KgNZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b45dc40d-8d74-4973-817d-52ba09ba93e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after transform =  0.8095238095238095\n"
          ]
        }
      ],
      "source": [
        "test_pred = NN(train_feats_rescaled, train_y, test_feats_rescaled)\n",
        "acc = Accuracy(test_y, test_pred)\n",
        "print('Accuracy after transform = ', acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qYX90Gqg-jO"
      },
      "source": [
        "All 2D linear transformations can be repreented by a transformation matrix. So what is the matrix associated with the rescaling function? Actually, we cannot represent rescaling with a matrix multiplication, because it is not a linear transform. Rescaling involves shifting the origin of the data, which is not allowed under linear transformations.\n",
        "\n",
        "We can represent rescaling as a matrix multiplication followed by a vector addition. Let our first feature vector be called X and second feature vector be called Y. Suppose we want to rescale a data point [a,b]\n",
        "\n",
        "$$ \\begin{equation}\n",
        " \\left\\{  \\begin{aligned}a' \\\\ b' \\end{aligned} \\right\\} =\n",
        " \\left\\{  \\begin{aligned} \\frac{a - min(X)}{max(X) - min(X)} \\\\ \\frac{b - min(Y)}{max(Y) - min(Y)} \\end{aligned} \\right\\} =\n",
        " \\left\\{  \\begin{aligned}&\\frac{1}{max(X)-min(X)} &0\\\\ &0 &\\frac{1}{max(Y)-min(Y)} \\end{aligned}\n",
        " \\right\\}\\left\\{  \\begin{aligned}a \\\\ b \\end{aligned} \\right\\} +\n",
        " \\left\\{  \\begin{aligned} \\frac{ -min(X)}{max(X) - min(X)} \\\\ \\frac{-min(Y)}{max(Y) - min(Y)} \\end{aligned} \\right\\}\n",
        "\\end{equation}$$\n",
        "\n",
        "You can verify this yourself if you wish, though it is not necessary.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}